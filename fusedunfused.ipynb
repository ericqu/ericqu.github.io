{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fusedunfused",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAQYxDTUOXoW+8vKvCchN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericqu/ericqu.github.io/blob/master/fusedunfused.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icg-T6bZ2rWQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "21e7a10e-e689-44e1-8afd-bd6bec312980"
      },
      "source": [
        "#for issue 40510\n",
        "!pip install tf-nightly\n",
        "!pip install tensorflow-model-optimization\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.3.0.dev20200618)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0.dev2020061901)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: tb-nightly<2.4.0a0,>=2.3.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0a20200618)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.29.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (47.3.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: tensorflow-model-optimization in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (0.1.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaU1zjRF_dyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8c601dfb-9a88-43ff-8cb6-3aa39df3a7bf"
      },
      "source": [
        "import gc\n",
        "import sys\n",
        "from datetime import date, datetime, time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sci\n",
        "import scipy.io as sio\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras.layers import (GRU, LSTM, Activation, Dense, Input,\n",
        "                                     SimpleRNN)\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "sns.set()\n",
        "print(sys.version)\n",
        "print(\"Tensor Flow:\",  tf.__version__)\n",
        "print(\"Keras: \", keras.__version__)\n",
        "print(\"Numpy: \", np.__version__)\n",
        "print(\"Seaborn: \", sns.__version__)\n",
        "print(\"scipy: \", sci.__version__)\n",
        "\n",
        "\n",
        "def increment_and_get(counter_path=\"counter.txt\", increment=True):\n",
        "    import os\n",
        "    value = 0\n",
        "    if os.path.exists(counter_path):\n",
        "        f = open(counter_path, \"r\")\n",
        "        value = int(f.readline())\n",
        "        f.close()\n",
        "        if increment is True:\n",
        "            value = value + 1\n",
        "    else:\n",
        "        if increment is True:\n",
        "            value = 1\n",
        "        else:\n",
        "            value = 0\n",
        "\n",
        "    if increment is True:\n",
        "        f = open(counter_path, \"w\")\n",
        "        f.write(str(value))\n",
        "        f.close()\n",
        "\n",
        "    return value\n",
        "\n",
        "\n",
        "model_iteration = increment_and_get(increment=False)\n",
        "\n",
        "\n",
        "def get_files_desc(path=\"nodefault\", cases=[0, 1, 2, 3, 4, 5, 6, 7]):\n",
        "    Cases_description = [\"Baseline\", \"Noise addition\", \"Adding respiratory movements for both mother and foetus\", \"Foetal movements added (helixoidal)\",\n",
        "                         \"Maternal and foetal similar heart rate (alternatively changes in the heart rates)\",\n",
        "                         \"Simulation of uterine contraction with noise and physiological based heart rate changes\",\n",
        "                         \"Ectopic beats\", \"Twin pregnancy\"\n",
        "                         ]\n",
        "\n",
        "    each_paths, each_descriptions = list(), list()\n",
        "    for i in cases:\n",
        "        full_path = path + str(i+1) + \".mat\"\n",
        "        each_paths.append(full_path)\n",
        "        description = Cases_description[i]\n",
        "        each_descriptions.append(description)\n",
        "    return each_paths, each_descriptions\n",
        "\n",
        "\n",
        "# cfg_cases_list = [2, 3, 4, 5]\n",
        "cfg_cases_list = [1]\n",
        "cfg_usable_cases_list = range(len(cfg_cases_list))\n",
        "print (\"Usable Cases list:\", *cfg_usable_cases_list)\n",
        "\n",
        "\n",
        "# cfg_EL_list = [5, 6, 7, 10, 11, 12, 15, 16, 17, 20, 21, 22, 25, 26, 27, 30, 31, 32 ] # Electrodes we are going to use\n",
        "cfg_EL_list = range(3,34,5) # Electrodes we are going to use (from, to, step)\n",
        "cfg_usable_EL_list = range(len(cfg_cases_list)) \n",
        "print (\"Electrodes list:\", *cfg_EL_list)\n",
        "\n",
        "file_paths, Cases_descriptions = get_files_desc(\n",
        "    \"fecgsyn_c\", cfg_cases_list)\n",
        "print(\"file_paths:\", file_paths)\n",
        "print(\"Cases_descriptions\", Cases_descriptions)\n",
        "\n",
        "# configuration variables\n",
        "cfg_mixture_gain = 100.0 \n",
        "cfg_mother_gain = 100.0  \n",
        "cfg_foetus_gain = 10.0   \n",
        "cfg_in_len_seq = 250  # 350, 250, 150\n",
        "cfg_out_len_seq = 50\n",
        "cfg_batches_size = 500 # 5000 is too high - 4000 works at about same speed as 3000 ; 50 is 10 times slower than3000\n",
        "cfg_epochs = 1\n",
        "cfg_obs_ps = 500  # hertz\n",
        "cfg_storage_type_f = np.float16\n",
        "\n",
        "models = list()\n",
        "models.append(dict(name=\"baseline_\" + str(model_iteration), nb_neurons=20,\n",
        "                   files=file_paths, per_file_description=Cases_descriptions, electrode_list= cfg_EL_list))\n",
        "\n",
        "tf.random.set_seed(12345)\n",
        "print(\"Model iteration: \", model_iteration)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n",
            "Tensor Flow: 2.3.0-dev20200618\n",
            "Keras:  2.4.0\n",
            "Numpy:  1.18.5\n",
            "Seaborn:  0.10.1\n",
            "scipy:  1.4.1\n",
            "Usable Cases list: 0\n",
            "Electrodes list: 3 8 13 18 23 28 33\n",
            "file_paths: ['fecgsyn_c2.mat']\n",
            "Cases_descriptions ['Noise addition']\n",
            "Model iteration:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAidOokiAJ0t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ed3b4c2b-3e97-4d35-e536-9cbe1518dceb"
      },
      "source": [
        "def load_mat(path):\n",
        "    c_mat = sio.loadmat(path, variable_names=['out'])\n",
        "    mat_out_data = c_mat['out']\n",
        "    mat_out_type = mat_out_data.dtype\n",
        "    c_data = {n: mat_out_data[n][0, 0] for n in mat_out_type.names}\n",
        "    print(\"loading\", path, \" columns: \", str(\n",
        "        [n for n, v in c_data.items()]), \" EL, observations: \", c_data[\"mecg\"].shape)\n",
        "\n",
        "    mecg = np.array((c_data['mecg'] / cfg_mother_gain), dtype=cfg_storage_type_f)\n",
        "\n",
        "    fecg1 = np.array(c_data[\"fecg\"][0][0] / cfg_foetus_gain, dtype=cfg_storage_type_f)\n",
        "    fecg2 = np.zeros(fecg1.shape, dtype=np.float32)\n",
        "    fecg3 = np.zeros(fecg1.shape, dtype=np.float32)\n",
        "    fecg4 = np.zeros(fecg1.shape, dtype=np.float32)\n",
        "\n",
        "    mixture = np.array(c_data[\"mixture\"] / cfg_mixture_gain, dtype=cfg_storage_type_f)\n",
        "\n",
        "    # we have indexes, all is zero but the indexes\n",
        "    mqrs_i = np.array(c_data[\"mqrs\"], np.int64)\n",
        "    mqrs = np.zeros(fecg1.shape[1], dtype=np.int8) # not per electrodes\n",
        "    mqrs[mqrs_i] = 1;\n",
        "\n",
        "    fqrs_i = np.array(c_data[\"fqrs\"][0][0] , np.int64)\n",
        "    fqrs = np.zeros(fecg1.shape[1], dtype=np.int8) # not per electrodes\n",
        "    fqrs[fqrs_i] = 1;\n",
        "\n",
        "    return mecg, fecg1, fecg2, fecg3, fecg4, mixture, mqrs, fqrs\n",
        "\n",
        "all_mecg, all_fecg1, all_fecg2, all_fecg3, all_fecg4, all_mixture , all_mqrs , all_fqrs  = list(),list(), list(), list(), list(), list(), list(), list()\n",
        "\n",
        "for c_path in file_paths:\n",
        "    c_mecg, c_fecg1, c_fecg2, c_fecg3, c_fecg4, c_mixture, c_mqrs, c_fqrs = load_mat(c_path)\n",
        "    print(\"completed.\")\n",
        "\n",
        "    all_mecg.append(c_mecg)\n",
        "    all_fecg1.append(c_fecg1)\n",
        "    all_fecg2.append(c_fecg2)\n",
        "    all_fecg3.append(c_fecg3)\n",
        "    all_fecg4.append(c_fecg4)\n",
        "    all_mixture.append(c_mixture)\n",
        "    all_mqrs.append(c_mqrs)\n",
        "    all_fqrs.append(c_fqrs)\n",
        "\n",
        "all_mecg = np.array(all_mecg)\n",
        "all_fecg1 = np.array(all_fecg1)\n",
        "all_fecg2 = np.array(all_fecg2)\n",
        "all_fecg3 = np.array(all_fecg3)\n",
        "all_fecg4 = np.array(all_fecg4)\n",
        "all_mixture = np.array(all_mixture)\n",
        "all_mqrs = np.array(all_mqrs)\n",
        "all_fqrs = np.array(all_fqrs)\n",
        "\n",
        "\n",
        "print(\"Total obs (all_mixture.shape):\", all_mixture.shape)\n",
        "print(\"Total obs (all_fqrs.shape):\", all_fqrs.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading fecgsyn_c2.mat  columns:  ['mecg', 'mixture', 'mqrs', 'fqrs', 'fecg']  EL, observations:  (34, 20000)\n",
            "completed.\n",
            "Total obs (all_mixture.shape): (1, 34, 20000)\n",
            "Total obs (all_fqrs.shape): (1, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urRVwWMdAkjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "93650dd4-9ed0-4435-f2f5-5483f2931392"
      },
      "source": [
        "def prep_electrodes_array(x, ym, yf, yqm, yqf, l_seq, o_seq, els, cases):\n",
        "    gen_types = [\"original\", \"no_foetus\", \"no_signal\"]\n",
        "    \n",
        "    X, YM, YF1, YQM, YQF1 = None, None, None, None, None\n",
        "    for case in cases:\n",
        "        for el in els:\n",
        "            for gen_type in gen_types:\n",
        "                if X is None:  # First time\n",
        "                    X, YM, YF1, YQM, YQF1= prep_training_array(x[case, el], ym[case,el], yf[case,el], yqm[case], yqf[case], l_seq, o_seq, gen_type)\n",
        "                else:\n",
        "                    X_t, YM_t, YF1_t, YQM_t, YQF1_t = prep_training_array(x[case, el], ym[case,el], yf[case,el], yqm[case], yqf[case], l_seq, o_seq, gen_type)\n",
        "                    X = np.concatenate((X, X_t))\n",
        "                    YM = np.concatenate((YM, YM_t))\n",
        "                    YF1 = np.concatenate((YF1, YF1_t))\n",
        "                    YQM = np.concatenate((YQM, YQM_t))\n",
        "                    YQF1 = np.concatenate((YQF1, YQF1_t))\n",
        "\n",
        "    return X, YM, YF1, YQM, YQF1\n",
        "\n",
        "\n",
        "def prep_training_array(x, ym, yf, yqm, yqf, l_seq, o_seq, gen_type=\"original\"):\n",
        "    if (len(x) != len(ym)):\n",
        "        raise NameError(\"x and y have different lengths \" +\n",
        "                        len(x) + \" \" + len(ym) + \" cannot continue.\")\n",
        "\n",
        "    X = np.empty([len(x)-l_seq, l_seq, 1], dtype=cfg_storage_type_f)\n",
        "    YM = np.empty([len(x)-l_seq, o_seq, 1], dtype=cfg_storage_type_f)\n",
        "    YF1 = np.empty([len(x)-l_seq, o_seq, 1], dtype=cfg_storage_type_f)\n",
        "    YQM = np.empty([len(x)-l_seq, o_seq, 1], dtype=np.int8)\n",
        "    YQF1 = np.empty([len(x)-l_seq, o_seq, 1], dtype=np.int8)\n",
        "\n",
        "    step = 1\n",
        "    \n",
        "    for i in range(0, len(x)-(l_seq), step):\n",
        "        X[i] = x[i:i + l_seq].reshape(l_seq, 1)\n",
        "        YM[i] = ym[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "        YF1[i] = yf[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "        YQM[i] = yqm[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "        YQF1[i] = yqf[i + l_seq - o_seq: i + l_seq].reshape(o_seq, 1)\n",
        "\n",
        "    return X, YM, YF1, YQM, YQF1\n",
        "\n",
        "\n",
        "print(\"Data Preparation started\")\n",
        "print(\"training data\")\n",
        "X_train, Y_trainM, Y_trainF1 , Y_trainQM, Y_trainQF1 = prep_electrodes_array(\n",
        "    all_mixture, all_mecg, all_fecg1, all_mqrs, all_fqrs, cfg_in_len_seq , cfg_out_len_seq, cfg_EL_list, cfg_usable_cases_list)\n",
        "print(\"test data\")\n",
        "\n",
        "X_test, Y_testM, Y_testF1, Y_testQM, Y_testQF1 = prep_training_array(\n",
        "    all_mixture[0,8], all_mecg[0,8], all_fecg1[0,8], all_mqrs[0], all_fqrs[0], cfg_in_len_seq, cfg_out_len_seq)\n",
        "\n",
        "print(\"shuffling\")\n",
        "together = np.hstack((X_train, Y_trainM, Y_trainF1 , Y_trainQM, Y_trainQF1))\n",
        "np.random.shuffle(together)\n",
        "X_train, Y_trainM, Y_trainF1, Y_trainQM, Y_trainQF1 = np.hsplit(together, [cfg_in_len_seq,\n",
        "                                                                           cfg_in_len_seq+cfg_out_len_seq,\n",
        "                                                                           cfg_in_len_seq+cfg_out_len_seq *2,\n",
        "                                                                           cfg_in_len_seq+cfg_out_len_seq *3,])\n",
        "def debug_display(name , val):\n",
        "    print(\"debug:\", name,  val.shape, val.dtype , \"min :\", np.min(val), \"max:\", np.max(val))\n",
        "\n",
        "debug_display(\"X_train\", X_train)\n",
        "debug_display(\"Y_trainM\", Y_trainM)\n",
        "debug_display(\"Y_trainF1\", Y_trainF1)\n",
        "debug_display(\"Y_trainQM\", Y_trainQM)\n",
        "debug_display(\"Y_trainQF1\", Y_trainQF1)\n",
        "\n",
        "debug_display(\"X_test\", X_test)\n",
        "debug_display(\"Y_testM\", Y_testM)\n",
        "debug_display(\"Y_testF1\", Y_testF1)\n",
        "debug_display(\"Y_testQM\", Y_testQM)\n",
        "debug_display(\"Y_testQF1\", Y_testQF1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Preparation started\n",
            "training data\n",
            "test data\n",
            "shuffling\n",
            "debug: X_train (414750, 250, 1) float16 min : -283.8 max: 327.8\n",
            "debug: Y_trainM (414750, 50, 1) float16 min : -271.0 max: 327.8\n",
            "debug: Y_trainF1 (414750, 50, 1) float16 min : -1076.0 max: 431.5\n",
            "debug: Y_trainQM (414750, 50, 1) float16 min : 0.0 max: 1.0\n",
            "debug: Y_trainQF1 (414750, 50, 1) float16 min : 0.0 max: 1.0\n",
            "debug: X_test (19750, 250, 1) float16 min : -90.2 max: 177.5\n",
            "debug: Y_testM (19750, 50, 1) float16 min : -47.25 max: 140.1\n",
            "debug: Y_testF1 (19750, 50, 1) float16 min : -119.5 max: 431.5\n",
            "debug: Y_testQM (19750, 50, 1) int8 min : 0 max: 1\n",
            "debug: Y_testQF1 (19750, 50, 1) int8 min : 0 max: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEENJs2SBKW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b541c915-ec1d-4cfb-f5cc-c55a35b5c990"
      },
      "source": [
        "print(gc.collect())\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7iwK8cyBQjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "2381948c-076a-4037-eb59-ba61e585203b"
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "\n",
        "def define_model(length_of_sequences, batch_size=None, modelName=\"nonamegiven\"):\n",
        "    inp = Input(batch_shape=(batch_size, length_of_sequences, 1), name=\"inputs\")\n",
        "    lstmM = Bidirectional(LSTM(50, name=\"lstm_m\", return_sequences=True))(inp)\n",
        "    flat = Flatten()(lstmM)\n",
        "    denseM = Dense(50, kernel_regularizer=regularizers.l2(0.0001))(flat)\n",
        "    reshapeM = Reshape((50, 1))(denseM)\n",
        "    denseM = TimeDistributed(\n",
        "        Dense(1, kernel_regularizer=regularizers.l2(\n",
        "            0.0001), bias_initializer='zeros'),\n",
        "        input_shape=(50, 1))(reshapeM)\n",
        "    out_M = Reshape((50, 1), name=\"om\")(denseM)\n",
        "    model = Model(inputs=[inp], outputs=[out_M], name=modelName)\n",
        "    model.compile(\n",
        "        loss={\"om\": \"mean_squared_error\"},\n",
        "        optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "        metrics=['mae'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "def define_q_model(k_model): \n",
        "    q_aware_model = tfmot.quantization.keras.quantize_model(k_model)\n",
        "    q_aware_model.compile(\n",
        "        loss={\"quant_om\": \"mean_squared_error\", \"quant_of\": \"mean_squared_error\"},\n",
        "        optimizer=keras.optimizers.RMSprop(learning_rate=0.001), \n",
        "        metrics=['mae'])\n",
        "    \n",
        "    return q_aware_model\n",
        "    \n",
        "for m in models:\n",
        "    m[\"k_model\"] = define_model(\n",
        "        length_of_sequences=cfg_in_len_seq, modelName=m[\"name\"])\n",
        "    m[\"k_model\"].summary()\n",
        "    \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"baseline_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(None, 250, 1)]          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 250, 100)          20800     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25000)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                1250050   \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 50, 1)             0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 50, 1)             2         \n",
            "_________________________________________________________________\n",
            "om (Reshape)                 (None, 50, 1)             0         \n",
            "=================================================================\n",
            "Total params: 1,270,852\n",
            "Trainable params: 1,270,852\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YobjSjncBrqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a27d81cd-2847-494d-f542-ec845da65b46"
      },
      "source": [
        "# Training\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta=5, restore_best_weights= True)\n",
        "\n",
        "for m in models:\n",
        "    print (\"fitting\")\n",
        "    m[\"k_history\"] = m[\"k_model\"].fit(x=X_train, y=[Y_trainM, Y_trainF1], \n",
        "                                      batch_size=cfg_batches_size, epochs=cfg_epochs, verbose=1, validation_split=0.1, \n",
        "                                      callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fitting\n",
            "  1/747 [..............................] - ETA: 0s - loss: 1351.6111 - mae: 15.1670"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}